{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Estudo_de_caso_ML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathanbff/Ic-Machine-Learning/blob/main/Estudo_de_caso_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boRmLRMGIT3z"
      },
      "source": [
        "# Estudo de caso 1: Boston Housing\n",
        "\n",
        "## Grupo de IC em Machine Learning (Outubro/2020)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_eZpicmLx6T"
      },
      "source": [
        "*   O objetivo da atividade é o desenvolvimento de um projeto de Ciência de Dados do começo ao fim, passando pela abertura dos dados, análise descritiva das variáveis, criação de insights e modelagem preditiva de regressão;\n",
        "\n",
        "*   Os participantes serão divididos em grupos, terão duas semanas para o desenvolvimento do projeto e contarão com o apoio de praticantes de ML mais experientes;\n",
        "\n",
        "* No dia 23/10 (ou depois), as duplas farão uma apresentação de, no máximo 20/25 minutos, contando para os presentes sobre sua experiência, dificuldades, insights e resultados. É recomendado que o projeto seja desenvolvido e apresentado aos demais no formato de Notebook (Jupyter ou Google Colab);\n",
        "\n",
        "* O estudo de caso, além de ser uma introdução prática ao DS e ML, também será uma ótima oportunidade para que os participantes comecem a organizar um portfólio de projetos. Logo, é recomendado que todos os participantes criem uma conta no Github para subir os materiais após a finalização do projeto;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcfLIMB9jFzi"
      },
      "source": [
        "## Grupos\n",
        "\n",
        "\n",
        "1.   **Membros:** Kauê, Lucka, Pet\n",
        "\n",
        "     **Mentores:** Carlos, Rodrigo, Felipe\n",
        "\n",
        "\n",
        "\n",
        "2.   **Membros:** Gabriel, Jonathan\n",
        "\n",
        "     **Mentores:** Giulia, Verena, Felipe\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBoTEYMjMG6d"
      },
      "source": [
        "## Roteiro \n",
        "\n",
        "A ideia de existir um roteiro a ser seguido é a de facilitar o desenvolvimento do projeto. No entanto, as duplas devem se sentir a vontade para acrescentar/alterar coisas se sentirem a necessidade. O passo-a-passo básico seria o seguinte:\n",
        "\n",
        "1. Carregar os pacotes *Numpy, Pandas, Scikit-Learn, Matplotlib.pyplot, Seaborn*;\n",
        "2. Abrir a base de dados **Boston Housing** utilizando o Scikit-Learn. Aqui é interessante setar '*return_X_y=False*', pois a base vem com mais informações. Links úteis:\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html\n",
        "  - https://scikit-learn.org/stable/datasets/index.html#boston-dataset\n",
        "\n",
        "3. Entender o significado de cada uma das variáveis. Links úteis:\n",
        "  - https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
        "  - https://deepblue.lib.umich.edu/bitstream/handle/2027.42/22636/0000186.pdf\n",
        "\n",
        "4. Concatenar bases 'data' e 'target' e transformar base de dados em um Data Frame do Pandas;\n",
        "\n",
        "5. Fazer uma análise descritiva das variáveis (features/target), de forma isolada. Primeiramente descubra quais variáveis são contínuas e discretas e depois utilize o método '*describe*' do Pandas, interpretando os resultados (escala dos dados, variabilidade, quantis etc). Refinar a análise utilizando histogramas, gráficos de densidade, gráficos de barra e box-plots para entender como as variáveis estão distribuídas - para a parte gráfica, utilizar o Matplotlib ou Seaborn. Links úteis:\n",
        "  - https://felipemaiapolo.github.io/notebooks/stats.html\n",
        "\n",
        "6. Calcular e plotar a matriz de correlação entre as features. Interpretar a matriz de correlação - para plotar a matriz, utilizar *heatmap* do pacote Seaborn;\n",
        "\n",
        "7. Entendendo o real significado das features, teorizar sobre quais podem ter relação com o target e as possíveis explicações sobre as relações potenciais (não necessariamente causal). Após essa parte reflexiva, escolha 5 features e utilize gráficos (scatterplot, densidade conjunta, linhas de tendência, gráficos de barra etc) para tentar entender a relação entre as features escolhidas e a variável alvo - para a parte gráfica, utilizar o Matplotlib ou Seaborn. Calcular também a correlação de Pearson entre as features e a variável alvo;\n",
        "\n",
        "8. Separar features e target em dois numpy arrays X e y. Utilizar a função *'train_test_split'* para criar os arrays X_train, X_test, y_train, y_test. Dica: utilizar a opção 'random_state' e 'stratify'. Links úteis:\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "9. Utilizar a função *'train_test_split'* novamente para criar os arrays X_train2, X_val, y_train2, y_val a partir de X_train, y_train. Fazer a padronização das variáveis de X_train2, X_val com parâmetros estimados em X_train2. Links úteis:\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "\n",
        "10. Agora vamos escolher os melhores hiperparâmetros para o modelo de regressão linear. Escolher possível valores para os hiperparâmetros da regressão Ridge (penalidade l2) e Lasso (penalidade l1) e armazená-los em uma lista ou numpy array. Fazer um loop nos possíveis valores para os hiperparâmetros, sendo que a cada iteração você treinará um modelo com o conjunto (X_train2, y_train2) e avaliará o Erro Quadrático Médio (MSE) no conjunto de validação (X_val, y_val) - será necessáio utilizar a função 'predict' e 'mean_squared_error'. Armazene os melhores valores dos hiperparâmetros para a regressão Ridge e Lasso. Links úteis:\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
        "\n",
        "11. Fazer a padronização das variáveis não-binárias de X_train, X_test com parâmetros estimados em X_train;\n",
        "\n",
        "12. Treinar modelos de Regressão Linear sem regularização, com penalização l1 e com penalização l2 utilizando os dados (X_train, y_train). Para os casos que utiliza regularização, utilizar os hiperparâmetros ótimos. Links úteis:\n",
        "  - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        "13. Estimar o Erro Quadrático Médio no conjunto de teste (X_test, y_test) e comparar a performance dos 3 modelos finais;\n",
        "\n",
        "14. Interpretar/plotar os valores dos parâmetros estimados (\"coef_\") para cada um dos modelos de regressão. Ainda podemos escrever os modelos estimados da seguinte maneira:\n",
        "\n",
        "\\begin{align}\n",
        "  \\hat{y} = \\hat{\\beta}_0+\\hat{\\beta}_1 x_1+...+\\hat{\\beta}_d x_d\n",
        "\\end{align}\n",
        "\n",
        "15. Repetir as partes de regressão sem a padronização das variáveis e comparar os resultados;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIHjq6N5i9al"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}